{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CNN_MNIST_classification_pytorch_backend.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhishekjagtap1/Handwritten-digits-recognition/blob/main/CNN_MNIST_classification_pytorch_backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEcKoQd2rq6K"
      },
      "source": [
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4ZdVIcWrq6L"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bl3i6ybQrq6L",
        "outputId": "d5547836-de4e-44bd-cf2a-486e66e245ac"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('training on cpu')\n",
        "else:\n",
        "    print('training on gpu')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training on gpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JGCvQ54rq6L"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 25\n",
        "valid_size = 0.2\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
        "\n",
        "\n",
        "\n",
        "train_data = torchvision.datasets.MNIST('data', train=True, download= True, transform = transform)\n",
        "test_data = torchvision.datasets.MNIST('data', train= False, download = True, transform = transform)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtnrrfgErq6M"
      },
      "source": [
        "def split_indices(n, validation_size):\n",
        "    valid_indices = int(n*validation_size)\n",
        "    shuffle_indices = np.random.permutation(n)\n",
        "    return shuffle_indices[valid_indices:], shuffle_indices[:valid_indices]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls6dszjFrq6M",
        "outputId": "3f79ddbf-4bbc-4926-c216-5e34e70d494d"
      },
      "source": [
        "train_indices, valid_indices = split_indices(len(train_data), valid_size)\n",
        "print(len(train_indices), len(valid_indices))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_iGff1Urq6M",
        "outputId": "d0bf36ce-dc8a-482f-f2b6-16993fe29661"
      },
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "train_loader = DataLoader(train_data, batch_size = batch_size, sampler = train_sampler, num_workers = num_workers)\n",
        "\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "valid_loader = DataLoader(train_data, batch_size = batch_size, sampler = valid_sampler, num_workers= num_workers)\n",
        "\n",
        "classes = [0, 1 , 2 , 3, 4 , 5 , 6 , 7 , 8 , 9]\n",
        "num_classes = len(classes)\n",
        "print(num_classes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOkG4VsYrq6M",
        "outputId": "27f5750d-21c8-4cef-c53a-e3a35b1398cd"
      },
      "source": [
        "#cnn architecture\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        #first conv layer\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size = 2, stride = 1, padding = 0)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size = 2, stride = 1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size = 2, stride = 1)\n",
        "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size = 2, stride = 1)\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size = 2, stride = 1)\n",
        "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv6 = nn.Conv2d(256, 512, kernel_size = 2, stride = 1)\n",
        "        self.maxpool3 = nn.MaxPool2d(2,2)\n",
        "        #fully connected layer\n",
        "        self.fc1 = nn.Linear(512*2*2, 1024)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(1024, 256)\n",
        "        self.fc3 = nn.Linear(256, 64)\n",
        "        #output layer \n",
        "        self.fc4 = nn.Linear(64, num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "        #conv layer activation function, forward propogating\n",
        "        x = F.relu(self.conv1(x))#28*28*16\n",
        "        x = F.relu(self.conv2(x))#28*28*32\n",
        "        x = F.relu(self.conv3(x))#28*28*64\n",
        "        x= self.maxpool1(x)#14*14*64\n",
        "        x = F.relu(self.conv4(x))#14*14*128\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.conv5(x))#14*14*256\n",
        "        x = self.dropout(x)\n",
        "        x = self.maxpool2(x)#7*7*256\n",
        "        x = F.relu(self.conv6(x))#7*7*512\n",
        "        x= self.maxpool3(x)#3.5*3.5*512\n",
        "        #print('conv6 after maxpooling size', x.shape)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        #fc\n",
        "        x = x.view(-1, 512*2*2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        \n",
        "        #output layer\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "    \n",
        "    \n",
        "model = Net()\n",
        "print(model)\n",
        "\n",
        "if train_on_gpu:\n",
        "    model.cuda()\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (conv5): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv6): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1))\n",
            "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
            "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd8JEUrcrq6N"
      },
      "source": [
        "#loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euL9Et4qrq6N",
        "outputId": "7fb73a36-3ee2-473a-c13d-df1ebf7b51c9"
      },
      "source": [
        "#training the network\n",
        "n_epochs = 30\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    \n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    model.train()\n",
        "    for data, labels in train_loader:\n",
        "      if train_on_gpu:\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "            #initializing gradients zero\n",
        "            optimizer.zero_grad()\n",
        "            #forward propagate \n",
        "            output = model(data)\n",
        "            #loss\n",
        "            loss = criterion(output, labels)\n",
        "            #backpropogating \n",
        "            loss.backward()\n",
        "            #update parameters\n",
        "            optimizer.step()\n",
        "            \n",
        "            #calculating the training loss\n",
        "            train_loss += loss.item()*data.size(0)\n",
        "        \n",
        "        \n",
        "        \n",
        "    # validating the model  \n",
        "    model.eval()\n",
        "    \n",
        "    for data, labels in valid_loader:\n",
        "        if train_on_gpu:\n",
        "            data, labels = data.cuda(), labels.cuda()\n",
        "            \n",
        "            output = model(data)\n",
        "            loss = criterion(output, labels)\n",
        "            \n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "            \n",
        "    \n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    \n",
        "    \n",
        "    \n",
        "    ### print the losses accordingly for each epoch\n",
        "    \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "                        epoch, train_loss, valid_loss))\n",
        "    \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "      \n",
        "        \n",
        "\n",
        "\n",
        "    torch.save(model, 'MNIST_CNN_Pytorch')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 2.301883 \tValidation Loss: 2.301170\n",
            "Epoch: 2 \tTraining Loss: 2.301309 \tValidation Loss: 2.300985\n",
            "Epoch: 3 \tTraining Loss: 2.301195 \tValidation Loss: 2.301009\n",
            "Epoch: 4 \tTraining Loss: 2.300994 \tValidation Loss: 2.300899\n",
            "Epoch: 5 \tTraining Loss: 2.300617 \tValidation Loss: 2.300165\n",
            "Epoch: 6 \tTraining Loss: 2.298892 \tValidation Loss: 2.297064\n",
            "Epoch: 7 \tTraining Loss: 2.027823 \tValidation Loss: 0.756171\n",
            "Epoch: 8 \tTraining Loss: 0.366480 \tValidation Loss: 0.170297\n",
            "Epoch: 9 \tTraining Loss: 0.161318 \tValidation Loss: 0.126596\n",
            "Epoch: 10 \tTraining Loss: 0.115281 \tValidation Loss: 0.095575\n",
            "Epoch: 11 \tTraining Loss: 0.092325 \tValidation Loss: 0.073457\n",
            "Epoch: 12 \tTraining Loss: 0.076726 \tValidation Loss: 0.065248\n",
            "Epoch: 13 \tTraining Loss: 0.067156 \tValidation Loss: 0.056973\n",
            "Epoch: 14 \tTraining Loss: 0.059593 \tValidation Loss: 0.053939\n",
            "Epoch: 15 \tTraining Loss: 0.051966 \tValidation Loss: 0.044223\n",
            "Epoch: 16 \tTraining Loss: 0.047038 \tValidation Loss: 0.043262\n",
            "Epoch: 17 \tTraining Loss: 0.043074 \tValidation Loss: 0.041023\n",
            "Epoch: 18 \tTraining Loss: 0.040685 \tValidation Loss: 0.037579\n",
            "Epoch: 19 \tTraining Loss: 0.036536 \tValidation Loss: 0.035428\n",
            "Epoch: 20 \tTraining Loss: 0.034376 \tValidation Loss: 0.040637\n",
            "Epoch: 21 \tTraining Loss: 0.032751 \tValidation Loss: 0.033404\n",
            "Epoch: 22 \tTraining Loss: 0.029467 \tValidation Loss: 0.033993\n",
            "Epoch: 23 \tTraining Loss: 0.029369 \tValidation Loss: 0.030947\n",
            "Epoch: 24 \tTraining Loss: 0.027132 \tValidation Loss: 0.030325\n",
            "Epoch: 25 \tTraining Loss: 0.024706 \tValidation Loss: 0.029396\n",
            "Epoch: 26 \tTraining Loss: 0.023607 \tValidation Loss: 0.033312\n",
            "Epoch: 27 \tTraining Loss: 0.023647 \tValidation Loss: 0.028177\n",
            "Epoch: 28 \tTraining Loss: 0.021707 \tValidation Loss: 0.030241\n",
            "Epoch: 29 \tTraining Loss: 0.020426 \tValidation Loss: 0.033522\n",
            "Epoch: 30 \tTraining Loss: 0.019821 \tValidation Loss: 0.028917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjCms4zlwKfE",
        "outputId": "79f0729d-c7cf-4c3c-b8da-489f97849ef1"
      },
      "source": [
        "model = torch.load('MNIST_CNN_Pytorch')\r\n",
        "model.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv4): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv6): Conv2d(256, 512, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "  (fc3): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJaXQUjkrq6O",
        "outputId": "4a8bc8ea-e9fb-41e1-ebf8-e18a0111d3d3"
      },
      "source": [
        "#testing the network on new data\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, num_workers = num_workers)\n",
        "\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "for data, labels, in test_loader:\n",
        "    if train_on_gpu:\n",
        "        data, labels =data.cuda(), labels.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        test_loss += loss.item()*data.size(0)\n",
        "\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    \n",
        "        for i in range(batch_size):\n",
        "            label = labels.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            classes[i], 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.022681\n",
            "\n",
            "Test Accuracy of     0: 99% (975/980)\n",
            "Test Accuracy of     1: 99% (1133/1135)\n",
            "Test Accuracy of     2: 99% (1024/1032)\n",
            "Test Accuracy of     3: 99% (1004/1010)\n",
            "Test Accuracy of     4: 99% (981/982)\n",
            "Test Accuracy of     5: 98% (883/892)\n",
            "Test Accuracy of     6: 99% (950/958)\n",
            "Test Accuracy of     7: 99% (1023/1028)\n",
            "Test Accuracy of     8: 98% (960/974)\n",
            "Test Accuracy of     9: 98% (991/1009)\n",
            "\n",
            "Test Accuracy (Overall): 99% (9924/10000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}